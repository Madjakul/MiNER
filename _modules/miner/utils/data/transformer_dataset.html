<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>miner.utils.data.transformer_dataset &mdash; MiNER  documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/sphinx_highlight.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../../index.html" class="icon icon-home">
            MiNER
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../installation.html#dependencies">Dependencies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../installation.html#install">Install</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../quickstart.html">How to Use MiNER</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../quickstart.html#running-with-provided-datasets">Running with Provided Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../quickstart.html#running-with-custom-datasets">Running with Custom Datasets</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../overview.html">Overview</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../overview.html#explanation">Explanation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../overview.html#benchmark">Benchmark</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../miner/modules/transformer.html">Transformer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../miner/modules/transformer.html#miner.modules.transformer.RoBERTa"><code class="docutils literal notranslate"><span class="pre">RoBERTa</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/transformer.html#miner.modules.transformer.RoBERTa.model"><code class="docutils literal notranslate"><span class="pre">RoBERTa.model</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../miner/modules/base_crf.html">BaseCRF</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../miner/modules/base_crf.html#miner.modules.base_crf.BaseCRF"><code class="docutils literal notranslate"><span class="pre">BaseCRF</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/base_crf.html#miner.modules.base_crf.BaseCRF.num_tags"><code class="docutils literal notranslate"><span class="pre">BaseCRF.num_tags</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/base_crf.html#miner.modules.base_crf.BaseCRF.start_transitions"><code class="docutils literal notranslate"><span class="pre">BaseCRF.start_transitions</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/base_crf.html#miner.modules.base_crf.BaseCRF.device"><code class="docutils literal notranslate"><span class="pre">BaseCRF.device</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/base_crf.html#miner.modules.base_crf.BaseCRF.end_transitions"><code class="docutils literal notranslate"><span class="pre">BaseCRF.end_transitions</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/base_crf.html#miner.modules.base_crf.BaseCRF.transitions"><code class="docutils literal notranslate"><span class="pre">BaseCRF.transitions</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/base_crf.html#miner.modules.base_crf.BaseCRF.forward"><code class="docutils literal notranslate"><span class="pre">BaseCRF.forward()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/base_crf.html#miner.modules.base_crf.BaseCRF.marginal_probabilities"><code class="docutils literal notranslate"><span class="pre">BaseCRF.marginal_probabilities()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/base_crf.html#miner.modules.base_crf.BaseCRF.viterbi_decode"><code class="docutils literal notranslate"><span class="pre">BaseCRF.viterbi_decode()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../miner/modules/partial_crf.html">PartialCRF</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../miner/modules/partial_crf.html#miner.modules.partial_crf.PartialCRF"><code class="docutils literal notranslate"><span class="pre">PartialCRF</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/partial_crf.html#miner.modules.partial_crf.PartialCRF.q"><code class="docutils literal notranslate"><span class="pre">PartialCRF.q</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/partial_crf.html#miner.modules.partial_crf.PartialCRF.forward"><code class="docutils literal notranslate"><span class="pre">PartialCRF.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../miner/modules/partial_ner.html">PartialNER</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../miner/modules/partial_ner.html#miner.modules.partial_ner.PartialNER"><code class="docutils literal notranslate"><span class="pre">PartialNER</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/partial_ner.html#miner.modules.partial_ner.PartialNER.device"><code class="docutils literal notranslate"><span class="pre">PartialNER.device</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/partial_ner.html#miner.modules.partial_ner.PartialNER.transformer"><code class="docutils literal notranslate"><span class="pre">PartialNER.transformer</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/partial_ner.html#miner.modules.partial_ner.PartialNER.linear_dropout"><code class="docutils literal notranslate"><span class="pre">PartialNER.linear_dropout</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/partial_ner.html#miner.modules.partial_ner.PartialNER.fc"><code class="docutils literal notranslate"><span class="pre">PartialNER.fc</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/partial_ner.html#miner.modules.partial_ner.PartialNER.crf"><code class="docutils literal notranslate"><span class="pre">PartialNER.crf</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/partial_ner.html#miner.modules.partial_ner.PartialNER.forward"><code class="docutils literal notranslate"><span class="pre">PartialNER.forward()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/partial_ner.html#miner.modules.partial_ner.PartialNER.marginal_probabilities"><code class="docutils literal notranslate"><span class="pre">PartialNER.marginal_probabilities()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/partial_ner.html#miner.modules.partial_ner.PartialNER.viterbi_decode"><code class="docutils literal notranslate"><span class="pre">PartialNER.viterbi_decode()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../miner/modules/smooth_ner.html">SmoothNER</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../miner/modules/smooth_ner.html#miner.modules.smooth_ner.SmoothNER"><code class="docutils literal notranslate"><span class="pre">SmoothNER</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/smooth_ner.html#miner.modules.smooth_ner.SmoothNER.device"><code class="docutils literal notranslate"><span class="pre">SmoothNER.device</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/smooth_ner.html#miner.modules.smooth_ner.SmoothNER.transformer"><code class="docutils literal notranslate"><span class="pre">SmoothNER.transformer</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/smooth_ner.html#miner.modules.smooth_ner.SmoothNER.linear_dropout"><code class="docutils literal notranslate"><span class="pre">SmoothNER.linear_dropout</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/smooth_ner.html#miner.modules.smooth_ner.SmoothNER.fc"><code class="docutils literal notranslate"><span class="pre">SmoothNER.fc</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/smooth_ner.html#miner.modules.smooth_ner.SmoothNER.kl_loss"><code class="docutils literal notranslate"><span class="pre">SmoothNER.kl_loss</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/smooth_ner.html#miner.modules.smooth_ner.SmoothNER.decode"><code class="docutils literal notranslate"><span class="pre">SmoothNER.decode()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/smooth_ner.html#miner.modules.smooth_ner.SmoothNER.forward"><code class="docutils literal notranslate"><span class="pre">SmoothNER.forward()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/modules/smooth_ner.html#miner.modules.smooth_ner.SmoothNER.get_proba"><code class="docutils literal notranslate"><span class="pre">SmoothNER.get_proba()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../miner/trainers/transformer_trainer.html">TransformerTrainer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../miner/trainers/transformer_trainer.html#miner.trainers.transformer_trainer.TransformerTrainer"><code class="docutils literal notranslate"><span class="pre">TransformerTrainer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/transformer_trainer.html#miner.trainers.transformer_trainer.TransformerTrainer.training_args"><code class="docutils literal notranslate"><span class="pre">TransformerTrainer.training_args</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/transformer_trainer.html#miner.trainers.transformer_trainer.TransformerTrainer.trainer"><code class="docutils literal notranslate"><span class="pre">TransformerTrainer.trainer</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/transformer_trainer.html#miner.trainers.transformer_trainer.TransformerTrainer.train"><code class="docutils literal notranslate"><span class="pre">TransformerTrainer.train()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../miner/trainers/partial_ner_trainer.html">PartialNERTrainer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../miner/trainers/partial_ner_trainer.html#miner.trainers.partial_ner_trainer.PartialNERTrainer"><code class="docutils literal notranslate"><span class="pre">PartialNERTrainer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/partial_ner_trainer.html#miner.trainers.partial_ner_trainer.PartialNERTrainer.ner"><code class="docutils literal notranslate"><span class="pre">PartialNERTrainer.ner</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/partial_ner_trainer.html#miner.trainers.partial_ner_trainer.PartialNERTrainer.epochs"><code class="docutils literal notranslate"><span class="pre">PartialNERTrainer.epochs</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/partial_ner_trainer.html#miner.trainers.partial_ner_trainer.PartialNERTrainer.device"><code class="docutils literal notranslate"><span class="pre">PartialNERTrainer.device</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/partial_ner_trainer.html#miner.trainers.partial_ner_trainer.PartialNERTrainer.ner_path"><code class="docutils literal notranslate"><span class="pre">PartialNERTrainer.ner_path</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/partial_ner_trainer.html#miner.trainers.partial_ner_trainer.PartialNERTrainer.idx2label"><code class="docutils literal notranslate"><span class="pre">PartialNERTrainer.idx2label</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/partial_ner_trainer.html#miner.trainers.partial_ner_trainer.PartialNERTrainer.loss_fn"><code class="docutils literal notranslate"><span class="pre">PartialNERTrainer.loss_fn</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/partial_ner_trainer.html#miner.trainers.partial_ner_trainer.PartialNERTrainer.clip"><code class="docutils literal notranslate"><span class="pre">PartialNERTrainer.clip</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/partial_ner_trainer.html#miner.trainers.partial_ner_trainer.PartialNERTrainer.sam"><code class="docutils literal notranslate"><span class="pre">PartialNERTrainer.sam</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/partial_ner_trainer.html#miner.trainers.partial_ner_trainer.PartialNERTrainer.optimizer"><code class="docutils literal notranslate"><span class="pre">PartialNERTrainer.optimizer</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/partial_ner_trainer.html#miner.trainers.partial_ner_trainer.PartialNERTrainer.lrs"><code class="docutils literal notranslate"><span class="pre">PartialNERTrainer.lrs</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/partial_ner_trainer.html#miner.trainers.partial_ner_trainer.PartialNERTrainer.train"><code class="docutils literal notranslate"><span class="pre">PartialNERTrainer.train()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../miner/trainers/smooth_ner_trainer.html">SmoothNERTrainer</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../miner/trainers/smooth_ner_trainer.html#miner.trainers.smooth_ner_trainer.SmoothNERTrainer"><code class="docutils literal notranslate"><span class="pre">SmoothNERTrainer</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/smooth_ner_trainer.html#miner.trainers.smooth_ner_trainer.SmoothNERTrainer.best_train_loss"><code class="docutils literal notranslate"><span class="pre">SmoothNERTrainer.best_train_loss</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/smooth_ner_trainer.html#miner.trainers.smooth_ner_trainer.SmoothNERTrainer.best_f1"><code class="docutils literal notranslate"><span class="pre">SmoothNERTrainer.best_f1</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/smooth_ner_trainer.html#miner.trainers.smooth_ner_trainer.SmoothNERTrainer.smooth_ner"><code class="docutils literal notranslate"><span class="pre">SmoothNERTrainer.smooth_ner</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/smooth_ner_trainer.html#miner.trainers.smooth_ner_trainer.SmoothNERTrainer.max_length"><code class="docutils literal notranslate"><span class="pre">SmoothNERTrainer.max_length</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/smooth_ner_trainer.html#miner.trainers.smooth_ner_trainer.SmoothNERTrainer.idx2label"><code class="docutils literal notranslate"><span class="pre">SmoothNERTrainer.idx2label</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/smooth_ner_trainer.html#miner.trainers.smooth_ner_trainer.SmoothNERTrainer.ner_path"><code class="docutils literal notranslate"><span class="pre">SmoothNERTrainer.ner_path</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/smooth_ner_trainer.html#miner.trainers.smooth_ner_trainer.SmoothNERTrainer.epochs"><code class="docutils literal notranslate"><span class="pre">SmoothNERTrainer.epochs</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/smooth_ner_trainer.html#miner.trainers.smooth_ner_trainer.SmoothNERTrainer.accumulation_steps"><code class="docutils literal notranslate"><span class="pre">SmoothNERTrainer.accumulation_steps</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/smooth_ner_trainer.html#miner.trainers.smooth_ner_trainer.SmoothNERTrainer.device"><code class="docutils literal notranslate"><span class="pre">SmoothNERTrainer.device</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/smooth_ner_trainer.html#miner.trainers.smooth_ner_trainer.SmoothNERTrainer.optimizer"><code class="docutils literal notranslate"><span class="pre">SmoothNERTrainer.optimizer</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/smooth_ner_trainer.html#miner.trainers.smooth_ner_trainer.SmoothNERTrainer.scheduler"><code class="docutils literal notranslate"><span class="pre">SmoothNERTrainer.scheduler</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/smooth_ner_trainer.html#miner.trainers.smooth_ner_trainer.SmoothNERTrainer.save_model"><code class="docutils literal notranslate"><span class="pre">SmoothNERTrainer.save_model()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/smooth_ner_trainer.html#miner.trainers.smooth_ner_trainer.SmoothNERTrainer.train"><code class="docutils literal notranslate"><span class="pre">SmoothNERTrainer.train()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/trainers/smooth_ner_trainer.html#miner.trainers.smooth_ner_trainer.SmoothNERTrainer.wandb_log"><code class="docutils literal notranslate"><span class="pre">SmoothNERTrainer.wandb_log()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../miner/utils/data/preprocessing.html">Preprocessing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../miner/utils/data/preprocessing.html#miner.utils.data.preprocessing.load_gazetteers"><code class="docutils literal notranslate"><span class="pre">load_gazetteers()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../miner/utils/data/preprocessing.html#miner.utils.data.preprocessing.read_conll"><code class="docutils literal notranslate"><span class="pre">read_conll()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../miner/utils/data/transformer_dataset.html">TransformerDataset</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../miner/utils/data/transformer_dataset.html#miner.utils.data.transformer_dataset.TransformerDataset"><code class="docutils literal notranslate"><span class="pre">TransformerDataset</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/transformer_dataset.html#miner.utils.data.transformer_dataset.TransformerDataset.mlm_ds"><code class="docutils literal notranslate"><span class="pre">TransformerDataset.mlm_ds</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/transformer_dataset.html#miner.utils.data.transformer_dataset.TransformerDataset.max_length"><code class="docutils literal notranslate"><span class="pre">TransformerDataset.max_length</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/transformer_dataset.html#miner.utils.data.transformer_dataset.TransformerDataset.train_corpus"><code class="docutils literal notranslate"><span class="pre">TransformerDataset.train_corpus</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/transformer_dataset.html#miner.utils.data.transformer_dataset.TransformerDataset.valid_corpus"><code class="docutils literal notranslate"><span class="pre">TransformerDataset.valid_corpus</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/transformer_dataset.html#miner.utils.data.transformer_dataset.TransformerDataset.tokenizer"><code class="docutils literal notranslate"><span class="pre">TransformerDataset.tokenizer</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/transformer_dataset.html#miner.utils.data.transformer_dataset.TransformerDataset.data_collator"><code class="docutils literal notranslate"><span class="pre">TransformerDataset.data_collator</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/transformer_dataset.html#miner.utils.data.transformer_dataset.TransformerDataset.add_vocab"><code class="docutils literal notranslate"><span class="pre">TransformerDataset.add_vocab()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../miner/utils/data/partial_ner_dataset.html">PartialNERDataset</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../miner/utils/data/partial_ner_dataset.html#miner.utils.data.partial_ner_dataset.PartialNERDataset"><code class="docutils literal notranslate"><span class="pre">PartialNERDataset</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/partial_ner_dataset.html#miner.utils.data.partial_ner_dataset.PartialNERDataset.device"><code class="docutils literal notranslate"><span class="pre">PartialNERDataset.device</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/partial_ner_dataset.html#miner.utils.data.partial_ner_dataset.PartialNERDataset.do_augment"><code class="docutils literal notranslate"><span class="pre">PartialNERDataset.do_augment</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/partial_ner_dataset.html#miner.utils.data.partial_ner_dataset.PartialNERDataset.max_length"><code class="docutils literal notranslate"><span class="pre">PartialNERDataset.max_length</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/partial_ner_dataset.html#miner.utils.data.partial_ner_dataset.PartialNERDataset.iterable_corpus"><code class="docutils literal notranslate"><span class="pre">PartialNERDataset.iterable_corpus</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/partial_ner_dataset.html#miner.utils.data.partial_ner_dataset.PartialNERDataset.iterable_labels"><code class="docutils literal notranslate"><span class="pre">PartialNERDataset.iterable_labels</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/partial_ner_dataset.html#miner.utils.data.partial_ner_dataset.PartialNERDataset.label2idx"><code class="docutils literal notranslate"><span class="pre">PartialNERDataset.label2idx</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/partial_ner_dataset.html#miner.utils.data.partial_ner_dataset.PartialNERDataset.tokenizer"><code class="docutils literal notranslate"><span class="pre">PartialNERDataset.tokenizer</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/partial_ner_dataset.html#miner.utils.data.partial_ner_dataset.PartialNERDataset.lm"><code class="docutils literal notranslate"><span class="pre">PartialNERDataset.lm</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/partial_ner_dataset.html#miner.utils.data.partial_ner_dataset.PartialNERDataset.align_labels"><code class="docutils literal notranslate"><span class="pre">PartialNERDataset.align_labels()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/partial_ner_dataset.html#miner.utils.data.partial_ner_dataset.PartialNERDataset.augmented_tokenize"><code class="docutils literal notranslate"><span class="pre">PartialNERDataset.augmented_tokenize()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/partial_ner_dataset.html#miner.utils.data.partial_ner_dataset.PartialNERDataset.tokenize"><code class="docutils literal notranslate"><span class="pre">PartialNERDataset.tokenize()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../miner/utils/data/smooth_ner_dataset.html">SmoothNERDataset</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../miner/utils/data/smooth_ner_dataset.html#miner.utils.data.smooth_ner_dataset.SmoothNERDataset"><code class="docutils literal notranslate"><span class="pre">SmoothNERDataset</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/smooth_ner_dataset.html#miner.utils.data.smooth_ner_dataset.SmoothNERDataset.partial_ner"><code class="docutils literal notranslate"><span class="pre">SmoothNERDataset.partial_ner</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/smooth_ner_dataset.html#miner.utils.data.smooth_ner_dataset.SmoothNERDataset.corpus"><code class="docutils literal notranslate"><span class="pre">SmoothNERDataset.corpus</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/smooth_ner_dataset.html#miner.utils.data.smooth_ner_dataset.SmoothNERDataset.max_length"><code class="docutils literal notranslate"><span class="pre">SmoothNERDataset.max_length</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/smooth_ner_dataset.html#miner.utils.data.smooth_ner_dataset.SmoothNERDataset.device"><code class="docutils literal notranslate"><span class="pre">SmoothNERDataset.device</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/smooth_ner_dataset.html#miner.utils.data.smooth_ner_dataset.SmoothNERDataset.labels"><code class="docutils literal notranslate"><span class="pre">SmoothNERDataset.labels</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/smooth_ner_dataset.html#miner.utils.data.smooth_ner_dataset.SmoothNERDataset.tokenizer"><code class="docutils literal notranslate"><span class="pre">SmoothNERDataset.tokenizer</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/smooth_ner_dataset.html#miner.utils.data.smooth_ner_dataset.SmoothNERDataset.lm"><code class="docutils literal notranslate"><span class="pre">SmoothNERDataset.lm</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/smooth_ner_dataset.html#miner.utils.data.smooth_ner_dataset.SmoothNERDataset.augmented_tokenize"><code class="docutils literal notranslate"><span class="pre">SmoothNERDataset.augmented_tokenize()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/smooth_ner_dataset.html#miner.utils.data.smooth_ner_dataset.SmoothNERDataset.enhanced_marginal_probabilities"><code class="docutils literal notranslate"><span class="pre">SmoothNERDataset.enhanced_marginal_probabilities()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/data/smooth_ner_dataset.html#miner.utils.data.smooth_ner_dataset.SmoothNERDataset.tokenize"><code class="docutils literal notranslate"><span class="pre">SmoothNERDataset.tokenize()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../miner/utils/crf_utils.html">CRF Utils</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../miner/utils/crf_utils.html#miner.utils.crf_utils.create_possible_tag_masks"><code class="docutils literal notranslate"><span class="pre">create_possible_tag_masks()</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../miner/utils/crf_utils.html#miner.utils.crf_utils.custom_argmax"><code class="docutils literal notranslate"><span class="pre">custom_argmax()</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../miner/utils/ner_utils.html">NER Utils</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../miner/utils/ner_utils.html#miner.utils.ner_utils.LRScheduler"><code class="docutils literal notranslate"><span class="pre">LRScheduler</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/ner_utils.html#miner.utils.ner_utils.LRScheduler.optimizer"><code class="docutils literal notranslate"><span class="pre">LRScheduler.optimizer</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/ner_utils.html#miner.utils.ner_utils.LRScheduler.patience"><code class="docutils literal notranslate"><span class="pre">LRScheduler.patience</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../miner/utils/ner_utils.html#miner.utils.ner_utils.LRScheduler.lr_scheduler"><code class="docutils literal notranslate"><span class="pre">LRScheduler.lr_scheduler</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../miner/utils/ner_utils.html#miner.utils.ner_utils.align_labels"><code class="docutils literal notranslate"><span class="pre">align_labels()</span></code></a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../license.html">MIT License</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../license.html#copyright-c-2023-madjakul">Copyright (c) 2023 Madjakul</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">MiNER</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">miner.utils.data.transformer_dataset</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for miner.utils.data.transformer_dataset</h1><div class="highlight"><pre>
<span></span><span class="c1"># miner/utils/data/transformer_dataset.py</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">datasets</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">DataCollatorForLanguageModeling</span>

<span class="kn">from</span> <span class="nn">miner.modules</span> <span class="kn">import</span> <span class="n">RoBERTa</span>
<span class="kn">from</span> <span class="nn">miner.utils.data</span> <span class="kn">import</span> <span class="n">preprocessing</span> <span class="k">as</span> <span class="n">pp</span>


<div class="viewcode-block" id="TransformerDataset"><a class="viewcode-back" href="../../../../miner/utils/data/transformer_dataset.html#miner.utils.data.transformer_dataset.TransformerDataset">[docs]</a><span class="k">class</span> <span class="nc">TransformerDataset</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Custom dataset used to pretrain Transformers checkpoints from</span>
<span class="sd">    **HuggingFace**.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    train_corpus: List[str]</span>
<span class="sd">        List of training texts.</span>
<span class="sd">    valid_corpus: List[str]</span>
<span class="sd">        List of validation texts.</span>
<span class="sd">    max_length: int</span>
<span class="sd">        Maximum sequence length.</span>
<span class="sd">    mlm_probability: float</span>
<span class="sd">        Proportion of words to mask from the training and validation corpus.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    mlm_ds:</span>
<span class="sd">        Maps the tokenising function to the **HuggingFace**&#39;s ``datasets``.</span>
<span class="sd">    max_length: int</span>
<span class="sd">        Maximum sequence length.</span>
<span class="sd">    train_corpus: list</span>
<span class="sd">        List of training sentences.</span>
<span class="sd">    valid_corpus: List[str]</span>
<span class="sd">        List of validation sentences.</span>
<span class="sd">    tokenizer: transformers.AutoTokenizer</span>
<span class="sd">        Object from ``AutoTokenizer``. The object depends on the language</span>
<span class="sd">        model used.</span>
<span class="sd">    data_collator: transformers.DataCollatorForLanguageModeling</span>
<span class="sd">        Data collator to mask a given proportion of word from the corpus before</span>
<span class="sd">        returning a tokenized and encoded version of it.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">train_corpus</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">valid_corpus</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">max_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">mlm_probability</span><span class="p">:</span> <span class="nb">float</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlm_ds</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_length</span> <span class="o">=</span> <span class="n">max_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_corpus</span> <span class="o">=</span> <span class="n">train_corpus</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_corpus</span> <span class="o">=</span> <span class="n">valid_corpus</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using roberta-base tokenizer&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="s2">&quot;roberta-base&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_build_mlm_dataset</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data_collator</span> <span class="o">=</span> <span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">mlm_probability</span><span class="o">=</span><span class="n">mlm_probability</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_build_mlm_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">train_ds</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_corpus</span><span class="p">}</span>
        <span class="n">valid_ds</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;text&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_corpus</span><span class="p">}</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">DatasetDict</span><span class="p">({</span>
            <span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">datasets</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">train_ds</span><span class="p">),</span>
            <span class="s2">&quot;valid&quot;</span><span class="p">:</span> <span class="n">datasets</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">valid_ds</span><span class="p">)</span>
        <span class="p">})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlm_ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_tokenize</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlm_ds</span><span class="o">.</span><span class="n">remove_columns</span><span class="p">([</span><span class="s2">&quot;text&quot;</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_tokenize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_length</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
            <span class="n">return_special_tokens_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
        <span class="p">)</span>

<div class="viewcode-block" id="TransformerDataset.add_vocab"><a class="viewcode-back" href="../../../../miner/utils/data/transformer_dataset.html#miner.utils.data.transformer_dataset.TransformerDataset.add_vocab">[docs]</a>    <span class="k">def</span> <span class="nf">add_vocab</span><span class="p">(</span> <span class="bp">self</span><span class="p">,</span> <span class="n">corpus</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">lm</span><span class="p">:</span> <span class="n">RoBERTa</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Adds new tokens to a pretrained LLM. The embedding of the added</span>
<span class="sd">        tokens are initialized using the mean of the already existing tokens</span>
<span class="sd">        plus some noise in order to avoid diverging too much from the initial</span>
<span class="sd">        distributions, thus converging faster during pretraining [1]_.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        corpus: ``list``</span>
<span class="sd">            List of tokens per document.</span>
<span class="sd">        lm: miner.modules.RoBERTa</span>
<span class="sd">            Pretrained large language model.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        ..  [1] Hewitt John. 2021. Initializing new word embeddings for</span>
<span class="sd">            pretrained language models. (2021). Retrieved April 24, 2023 from</span>
<span class="sd">            https://nlp.stanford.edu/~johnhew/vocab-expansion.html</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">new_tokens</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">token</span> <span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">corpus</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">pp</span><span class="o">.</span><span class="n">escape</span><span class="p">(</span><span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
        <span class="p">]</span>
        <span class="n">new_tokens</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">new_tokens</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="c1"># New tokens don&#39;t already exist</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span> <span class="sa">f</span><span class="s2">&quot;Adding </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">new_tokens</span><span class="p">)</span><span class="si">}</span><span class="s2"> new tokens to the vocabulary&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_tokens</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">new_tokens</span><span class="p">))</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Resizing the Language model&quot;</span><span class="p">)</span>
        <span class="n">lm</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">resize_token_embeddings</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">))</span>
        <span class="c1"># Computing the distribution of the new embeddings</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="c1"># embeddings = params[&quot;transformer.wte.weight&quot;]</span>
        <span class="n">embeddings_key</span> <span class="o">=</span> <span class="s2">&quot;roberta.embeddings.word_embeddings.weight&quot;</span>
        <span class="n">embeddings</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="n">embeddings_key</span><span class="p">]</span>
        <span class="n">pre_expansion_embeddings</span> <span class="o">=</span> <span class="n">embeddings</span><span class="p">[:</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">pre_expansion_embeddings</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">pre_expansion_embeddings</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">pre_expansion_embeddings</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="p">(</span><span class="n">pre_expansion_embeddings</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span>
        <span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="o">.</span><span class="n">MultivariateNormal</span><span class="p">(</span>
            <span class="n">mu</span><span class="p">,</span>
            <span class="n">covariance_matrix</span><span class="o">=</span><span class="mf">1e-5</span><span class="o">*</span><span class="n">sigma</span>
        <span class="p">)</span>
        <span class="c1"># Loading the new embeddings in the model</span>
        <span class="n">new_embeddings</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
            <span class="nb">tuple</span><span class="p">((</span><span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">))),</span>
            <span class="n">dim</span><span class="o">=</span><span class="mi">0</span>
        <span class="p">)</span>
        <span class="n">embeddings</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">new_embeddings</span>
        <span class="n">params</span><span class="p">[</span><span class="n">embeddings_key</span><span class="p">][</span><span class="o">-</span><span class="mi">3</span><span class="p">:,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">new_embeddings</span>
        <span class="n">lm</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">params</span><span class="p">)</span></div></div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Madjakul.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>